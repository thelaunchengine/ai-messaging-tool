import requests; from bs4 import BeautifulSoup; about_url = "https://www.arauto505.com/about-us/"; headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}; print(f"Testing About Us URL: {about_url}"); about_resp = requests.get(about_url, timeout=10, headers=headers); print(f"Status: {about_resp.status_code}"); about_soup = BeautifulSoup(about_resp.text, "html.parser"); main_content = about_soup.find("main") or about_soup.find("article") or about_soup.find("div", class_="content"); print(f"Main content found: {main_content is not None}"); paragraphs = main_content.find_all("p") if main_content else about_soup.find_all("p"); print(f"Total paragraphs found: {len(paragraphs)}"); content_parts = []; [content_parts.append(p.get_text(strip=True)) for p in paragraphs if p.get_text(strip=True) and len(p.get_text(strip=True)) > 20]; print(f"Content parts with >20 chars: {len(content_parts)}"); [print(f"Part {i+1}: {part[:100]}...") for i, part in enumerate(content_parts[:3])];
